{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Scalars (zero dimension tensor)\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "print(scalar.ndim) #dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the python number within a tensor (for one-element tensors)\n",
    "scalar.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 8])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Vectors\n",
    "vector = torch.tensor([7,8])\n",
    "print(vector)\n",
    "print(vector.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The shape of a vector tell how the elemts inside them are arranged. This has a shape of 2 (two entires) and is one dimentional\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "Dimesion: 2 (because its a 2x2 matrix)\n",
      "Shape: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "#Matrix\n",
    "matrix = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "print(matrix)\n",
    "print('Dimesion:',matrix.ndim,'(because its a 2x2 matrix)')\n",
    "print('Shape:',matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Dimesion: 3\n",
      "Shape: torch.Size([1, 3, 3]) (1 dimension of a 3x3 matrix)\n"
     ]
    }
   ],
   "source": [
    "#Tensors\n",
    "tensor = torch.tensor([[[1,2,3],\n",
    "                        [4,5,6],\n",
    "                        [7,8,9]]])\n",
    "print(tensor)\n",
    "print('Dimesion:',tensor.ndim)\n",
    "print('Shape:',tensor.shape,'(1 dimension of a 3x3 matrix)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
    "\n",
    "In essence:\n",
    "\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...\n",
    "\n",
    "As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0846, 0.5276, 0.5176, 0.1685],\n",
       "         [0.7727, 0.1149, 0.3130, 0.0834],\n",
       "         [0.7409, 0.5332, 0.1218, 0.0974]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor of random numbers\n",
    "random_tensor = torch.rand(size=(3,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you'll just want to fill tensors with zeros or ones.\n",
    "\n",
    "This happens a lot with masking (like masking some of the values in one tensor with zeros to let a model know not to learn them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor of zeros\n",
    "zeros = torch.zeros(size=(4,5))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Also a tensor of ones\n",
    "ones = torch.ones(size=(2,3))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(start=0,end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sometimes you might want one tensor of a certain type with the same shape as another tensor. For example, a tensor of all zeros with the same shape as a previous tensor.\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                            dtype=None,\n",
    "                            device=None,\n",
    "                            requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "float_32_tensor,float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
    "\n",
    "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 14, 15])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor operations\n",
    "tensor = torch.tensor([3,4,5])\n",
    "tensor+10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original tensors is unchanged: tensor([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "#Note that the values inside the tensor don't change unless they're reassigned\n",
    "tensor *10\n",
    "print('The original tensors is unchanged:', tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7, -6, -5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor - 10 #Subtract and reassign\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 10 #Add and reassign\n",
    "tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30, 40, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiplication can be done as:\n",
    "print(torch.multiply(tensor,10))\n",
    "#but the values are not reassigned:\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 16, 25])\n"
     ]
    }
   ],
   "source": [
    "#also\n",
    "print(tensor*tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element wise: tensor([1, 4, 9])\n",
      "matrix multiplication tensor(14)\n",
      "same as using @ tensor(14)\n"
     ]
    }
   ],
   "source": [
    "#Matrix multiplication (matmul)\n",
    "tensormul = torch.tensor([1,2,3])\n",
    "print('Element wise:', tensormul* tensormul)\n",
    "print('matrix multiplication', torch.matmul(tensormul,tensormul))\n",
    "print('same as using @', tensormul @ tensormul) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# See the difference in computational time between manual and authomatic method\n",
    "#Manually\n",
    "\n",
    "value = 0 \n",
    "for i in range(len(tensormul)):\n",
    "    value  =+ tensormul[i] * tensormul[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensormul,tensormul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common errors in deep learning (shape errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m8\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     10\u001b[0m tensor_A\u001b[38;5;241m.\u001b[39mshape, tensor_B\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m#cannot multiply (3x2)(3x2)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(tensor_A, tensor_B)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#Shapes need to be in the right way\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [4,5],\n",
    "                        [7,8]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7,5],\n",
    "                         [8,4],\n",
    "                         [4,8]], dtype=torch.float32)\n",
    "\n",
    "tensor_A.shape, tensor_B.shape #cannot multiply (3x2)(3x2)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) #shape error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [4., 5.],\n",
      "        [7., 8.]]) \n",
      "\n",
      "tensor([[7., 8., 4.],\n",
      "        [5., 4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# To multiply A and B we need to use the transpose so taht (3x2)(2x3)\n",
    "print(tensor_A,'\\n')\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17., 16., 20.],\n",
      "        [53., 52., 56.],\n",
      "        [89., 88., 92.]])\n"
     ]
    }
   ],
   "source": [
    "#So now we can see:\n",
    "print(torch.matmul(tensor_A, tensor_B.T)) #same with torch.mm(tensor_A,tensor_B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neural networks are full of matrix multiplications and dot products.\n",
    "\n",
    "The torch.nn.Linear() module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape of x: torch.Size([3, 2])\n",
      "\n",
      "Output: \n",
      " tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [5.6194, 2.6809, 0.4347, 0.5995, 0.4447, 3.2247],\n",
      "        [9.0019, 4.1326, 0.3980, 0.8125, 0.7585, 5.4656]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape:torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "#Choose a seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "#Linear uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2,\n",
    "                         out_features=6)\n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "\n",
    "print(f\"Input shape of x: {x.shape}\\n\")\n",
    "print(f\"Output: \\n {output}\\n\\nOutput shape:{output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor starting from 0 to 100 with 10 steps\n",
    "x = torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Minimum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n",
      "\n",
      " Same as:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(90), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some aggregation\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Minimum: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") #x.mean won't work\n",
    "print(f\"Sum: {x.sum()}\")\n",
    "\n",
    "print('\\n Same as:\\n')\n",
    "torch.min(x), torch.max(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensoor: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index of min value: 0\n",
      "Index of max value: 9\n"
     ]
    }
   ],
   "source": [
    "#It is useful to find the index of such (or any) value\n",
    "tens = torch.arange(0,100,10)\n",
    "print(f\"Tensoor: {tens}\")\n",
    "\n",
    "#Return the index of min and max\n",
    "print(f\"Index of min value: {tens.argmin()}\")\n",
    "print(f\"Index of max value: {tens.argmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change tensor datatype:\n",
    "A common issue with deep learning operations is having your tensors in different datatypes.\n",
    "Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor32 = torch.arange(10.,100.,10.)\n",
    "tensor32.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor16 = tensor32.type(torch.float16)\n",
    "tensor16.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int8"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor8 = tensor32.type(torch.int8)\n",
    "tensor8.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping, stacking, squeezing and unsqueezing: Reshape or change the dimensions of your tensors without actually changing the values inside them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a tensor\n",
    "x = torch.arange(1.,8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add an extra dimension\n",
    "x_reshaped = x.reshape(1,7)\n",
    "x_reshaped, x_reshaped.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the view\n",
    "z = x.view(1,7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#But changing the view changes the original tensor\n",
    "z[:, 0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can stack tensosrs on top\n",
    "x_stacked = torch.stack([x,x,x,x], dim=0) #0 along x and 1 along y\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove all single dimensions\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Can also unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "x_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), torch.Size([3, 224, 224]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rearrange the order of axes values\n",
    "x_original = torch.rand(size=(224,224,3))\n",
    "\n",
    "x_permuted = x_original.permute(2,0,1) #Return a view\n",
    "x_original.shape, x_permuted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
